{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating images with MX-Font model from a reference style\n",
    "In this example we'll generate images with trained MX-Font model from a reference style.\n",
    "If you want to generate multiple styles, please check using `eval.py` instead of using this example file (because it is much simpler to load the referece styles)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading packages\n",
    "* First, load the packages used in this code.\n",
    "* All of the packages are avilable in `pip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from sconf import Config\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* These modules are defined in this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "from datasets import read_font, render\n",
    "from utils import save_tensor_to_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build model\n",
    "* Build and load the trained model.\n",
    "* `weight_path` : \n",
    "    * The location of the trained model weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################################################\n",
    "#weight_path = \"/opt/mxfont/generator.pth\"  # path to weight to infer\n",
    "weight_path ='/opt/final-project-level2-cv-11/src/model/font_generator/mxfont/result/checkpoints/last.pth'\n",
    "########################################################\n",
    "\n",
    "cfg = Config(\"cfgs/eval.yaml\", default=\"cfgs/defaults.yaml\")\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Resize((128, 128)), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    ")\n",
    "decomposition = json.load(open(\"data/kor_decomposition.json\"))\n",
    "\n",
    "g_kwargs = cfg.get('g_args', {})\n",
    "gen = models.Generator(1, cfg.C, 1, **g_kwargs).cuda().eval()\n",
    "weight = torch.load(weight_path)\n",
    "if \"generator_ema\" in weight:\n",
    "    weight = weight[\"generator_ema\"]\n",
    "gen.load_state_dict(weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load reference images.\n",
    "* `ref_path`: \n",
    "    * The path of reference font or images.\n",
    "    * If you are using a ttf file, set this to the location of the ttf file.\n",
    "    * If you want to use rendered images, set this to the path to the directory which contains the reference images.\n",
    "* `extension`:\n",
    "    * If you are using image files, set this to their extension(png, jpg, etc..). \n",
    "    * This will be ignored if `use_ttf` is True.\n",
    "* `batch_size`:\n",
    "    * The number of images inferred at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "ref_path = \"/opt/final-project-level2-cv-11/src/model/font_generator/mxfont/data/images/test\"  # Path to the reference images/opt/mxfont/data/images/test/MaShanZheng-Regular\n",
    "extension = \"png\"  # Extension of the reference images\n",
    "batch_size = 3  # The batch size\n",
    "########################################################\n",
    "\n",
    "ref_paths = Path(ref_path).glob(f\"*.{extension}\")\n",
    "ref_imgs = torch.stack([transform(Image.open(str(p))) for p in ref_paths]).cuda()\n",
    "ref_batches = torch.split(ref_imgs, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extract style factors from reference images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_facts = {}\n",
    "\n",
    "for batch in ref_batches:\n",
    "    style_fact = gen.factorize(gen.encode(batch), 0)\n",
    "    for k in style_fact:\n",
    "        style_facts.setdefault(k, []).append(style_fact[k])\n",
    "        \n",
    "style_facts = {k: torch.cat(v).mean(0, keepdim=True) for k, v in style_facts.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Generate the images.\n",
    "* `gen_chars`: The characters to generate.\n",
    "* `save_dir`: Path to save the generated images.\n",
    "* `source_path`: Path to the font file used as the source font."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "gen_chars = \"åœ‹\"  # Characters to generate\n",
    "save_dir = Path(\"./results\")  # Directory where you want to save generated images\n",
    "source_path = \"/opt/final-project-level2-cv-11/src/model/font_generator/mxfont/data/ttfs/val/SeoulHangangB.ttf\"  # Path to the font file to render the source images\n",
    "########################################################\n",
    "\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "source_font = read_font(source_path)\n",
    "for char in gen_chars:\n",
    "    source_img = transform(render(source_font, char)).unsqueeze(0).cuda()\n",
    "    char_facts = gen.factorize(gen.encode(source_img), 1)\n",
    "    \n",
    "    gen_feats = gen.defactorize([style_facts, char_facts])\n",
    "    out = gen.decode(gen_feats).detach().cpu()[0]\n",
    "\n",
    "    path = save_dir / f\"{char}.png\"\n",
    "    save_tensor_to_image(out, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "a = cv2.imread(\"/opt/mxfont/data/images/test/kor/a-1.png\")\n",
    "b = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "c = cv2.cvtColor(b, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imwrite('/opt/mxfont/data/images/test/kor/b-1.png', c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Matplotlib requires numpy>=1.19; you have 1.16.6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m ImageFilter\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m Image\n\u001b[0;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m im \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(\u001b[39m'\u001b[39m\u001b[39m/opt/mxfont/results/W.png\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m im1 \u001b[39m=\u001b[39m im\u001b[39m.\u001b[39mfilter(ImageFilter\u001b[39m.\u001b[39mBLUR)\n",
      "File \u001b[0;32m/opt/conda/envs/best/lib/python3.8/site-packages/matplotlib/__init__.py:214\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[39mif\u001b[39;00m parse_version(module\u001b[39m.\u001b[39m__version__) \u001b[39m<\u001b[39m parse_version(minver):\n\u001b[1;32m    210\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMatplotlib requires \u001b[39m\u001b[39m{\u001b[39;00mmodname\u001b[39m}\u001b[39;00m\u001b[39m>=\u001b[39m\u001b[39m{\u001b[39;00mminver\u001b[39m}\u001b[39;00m\u001b[39m; \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    211\u001b[0m                               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39myou have \u001b[39m\u001b[39m{\u001b[39;00mmodule\u001b[39m.\u001b[39m__version__\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 214\u001b[0m _check_versions()\n\u001b[1;32m    217\u001b[0m \u001b[39m# The decorator ensures this always returns the same handler (and it is only\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[39m# attached once).\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mlru_cache()\n\u001b[1;32m    220\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_ensure_handler\u001b[39m():\n",
      "File \u001b[0;32m/opt/conda/envs/best/lib/python3.8/site-packages/matplotlib/__init__.py:210\u001b[0m, in \u001b[0;36m_check_versions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    208\u001b[0m module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mimport_module(modname)\n\u001b[1;32m    209\u001b[0m \u001b[39mif\u001b[39;00m parse_version(module\u001b[39m.\u001b[39m__version__) \u001b[39m<\u001b[39m parse_version(minver):\n\u001b[0;32m--> 210\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMatplotlib requires \u001b[39m\u001b[39m{\u001b[39;00mmodname\u001b[39m}\u001b[39;00m\u001b[39m>=\u001b[39m\u001b[39m{\u001b[39;00mminver\u001b[39m}\u001b[39;00m\u001b[39m; \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    211\u001b[0m                       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39myou have \u001b[39m\u001b[39m{\u001b[39;00mmodule\u001b[39m.\u001b[39m__version__\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: Matplotlib requires numpy>=1.19; you have 1.16.6"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFilter\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "im = Image.open('/opt/mxfont/results/W.png')\n",
    "\n",
    "im1 = im.filter(ImageFilter.BLUR)\n",
    "\n",
    "im2 = im.filter(ImageFilter.MinFilter(3))\n",
    "im3 = im.filter(ImageFilter.MinFilter) \n",
    "\n",
    "plt.imshow(im3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/opt/final-project-level2-cv-11/src/model/font_generator/mxfont/data/kor_decomposition.json',\n",
       " '/opt/final-project-level2-cv-11/src/model/font_generator/mxfont/data/kor_primals.json',\n",
       " '/opt/final-project-level2-cv-11/src/model/font_generator/mxfont/data/ttfs',\n",
       " '/opt/final-project-level2-cv-11/src/model/font_generator/mxfont/data/chn_gen.json',\n",
       " '/opt/final-project-level2-cv-11/src/model/font_generator/mxfont/data/chn_decomposition.json',\n",
       " '/opt/final-project-level2-cv-11/src/model/font_generator/mxfont/data/chn_primals.json',\n",
       " '/opt/final-project-level2-cv-11/src/model/font_generator/mxfont/data/kor_gen.json',\n",
       " '/opt/final-project-level2-cv-11/src/model/font_generator/mxfont/data/images']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "file_list = glob.glob('/opt/final-project-level2-cv-11/src/model/font_generator/mxfont/data/*')\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['props', 'glyphs', 'sfnt_names', 'input', 'output', '# vim: set et sw=2 ts=2 sts=2:'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "os.environ['HOME'] = \"/opt/final-project-level2-cv-11\"\n",
    "with open (os.path.join(os.getenv(\"HOME\"),\"src/model/svg2ttf/example.json\" ), \"r\") as f:\n",
    "                font_json = json.load(f)\n",
    "                \n",
    "font_json.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mxfont",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "753288dc2ee827038f50f223514d461f627f95eb9e9cb8557abeeaa000339686"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
